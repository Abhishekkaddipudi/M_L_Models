{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa6f25a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Importing Libraries</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a6d5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle as pkl\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#ignoring the warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b26098",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Loading Dataset</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e8b9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab8a9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5dca743",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "406f7622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b654cd",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "    <h2 style=\"margin:200px\"></h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17581267",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Linear Regression</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f49115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self,learning_rate=0.1,iteration=5000):\n",
    "        \"\"\"LinearRegression implementation \n",
    "        Learning_rate = rate of gradient descent reaching minima\n",
    "        iteration = number of iteration - (can only be integer)\"\"\"\n",
    "        self.itr=iteration\n",
    "        self.lr=learning_rate\n",
    "        self.weights=None\n",
    "        self.bias=None\n",
    "        self.samples=0\n",
    "        self.features=0\n",
    "        \n",
    "    def _init_params(self):\n",
    "        #initializing the parameters\n",
    "        self.weights=np.zeros(self.features)\n",
    "        self.bias=0\n",
    "        \n",
    "    def _calculate_cost(self, y, y_pred):\n",
    "        return (1 / (2*self.samples)) * np.sum(np.square(y_pred-y))\n",
    "        #cost function - repeat untill convergence\n",
    "        \n",
    "    def _get_prediction(self,X):\n",
    "        return np.dot(X,self.weights)+self.bias\n",
    "        #get the prediction for the current values of weights and bias\n",
    "        \n",
    "    def _update_params(self,dw,db):\n",
    "        self.weights-=self.lr*dw\n",
    "        self.bias-=self.lr*db\n",
    "        #lr - learning rate\n",
    "        \n",
    "    def _get_gradient(self,X,y,y_pred):\n",
    "        error=y_pred-y\n",
    "        dw=(1/self.samples)*np.dot(X.T,error)\n",
    "        db=(1/self.samples)*np.sum(error)\n",
    "        #partial derivative\n",
    "        return dw,db\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        #fit function trains the model\n",
    "        self.samples,self.features=X.shape\n",
    "        self._init_params()\n",
    "        try:\n",
    "            for i in range(self.itr):\n",
    "                y_pred=self._get_prediction(X)\n",
    "                cost=self._calculate_cost(y,y_pred)\n",
    "                dw,db=self._get_gradient(X,y,y_pred)\n",
    "                self._update_params(dw,db)\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"The Cost in iteration {i}----->{cost}\") \n",
    "        except ValueError:\n",
    "            print(\"nan value or some unidentified values found\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception found {e}\")      \n",
    "    def predict(self,X):\n",
    "        return self._get_prediction(X)\n",
    "        #calls _get_prediction method\n",
    "        \n",
    "    def save_model(self):\n",
    "        try:\n",
    "            file = open('Linear_regression.pkl', 'wb')\n",
    "            pkl.dump(self,file)\n",
    "            file.close()\n",
    "            #save the model for deployment or for future training\n",
    "        except Exception as e:\n",
    "            print(f\"Exception found {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566b4c5",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "    <h2 style=\"margin:400px\"></h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3704e8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Ridge (L2 Regularization)</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57c03501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgePenalty:\n",
    "    \"\"\"Lasso Regularization class \n",
    "    \"\"\"\n",
    "    def __init__(self,alpha):\n",
    "        self.alpha=alpha\n",
    "    def __call__(self,w):\n",
    "        return self.alpha*np.sum(np.square(w))\n",
    "    def derivation(self,w):\n",
    "        return self.alpha*2*w\n",
    "\n",
    "class Ridge(LinearRegression):\n",
    "    def __init__(self,alpha,learning_rate=0.1,iteration=5000):\n",
    "        \"\"\"Ridge Regression implementation - inherits Linear Regression\n",
    "        alpha - hyperparameter\n",
    "        Learning_rate = rate of gradient descent reaching minima\n",
    "        iteration = number of iteration - (can only be integer)\"\"\"\n",
    "        self.regularization=Ridgepenalty(alpha)\n",
    "        #initialize the Ridge penalty        \n",
    "        super().__init__(learning_rate,iteration)\n",
    "        #initialize the super class i.e LinearRegression\n",
    "\n",
    "    def _calculate_cost(self, y, y_pred):\n",
    "        return super()._calculate_cost(y,y_pred)+self.regularization(self.weights)\n",
    "        #cost functon\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        try:\n",
    "            self.samples,self.features=X.shape\n",
    "            super()._init_params()\n",
    "            for i in range(self.itr):\n",
    "                y_pred=super()._get_prediction(X)\n",
    "                cost=self._calculate_cost(y,y_pred)\n",
    "                dw,db=super()._get_gradient(X,y,y_pred)\n",
    "                dw+=self.regularization.derivation(self.weights)\n",
    "                self._update_params(dw,db)\n",
    "                if i % 100 ==0:\n",
    "                    print(f\"The Cost in iteration {i}----->{cost}\")\n",
    "                    \n",
    "        except ValueError:\n",
    "            print(\"nan value or some unidentified values found\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception found {e}\")\n",
    "                \n",
    "    def predict(self,X):\n",
    "        return super().predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d1625",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Lasso (L1 Regularization)</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2333deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoPenalty:\n",
    "    \"\"\"Lasso Regularization class \"\"\"\n",
    "    def __init__(self,alpha):\n",
    "        self.alpha=alpha\n",
    "    def __call__(self,w):\n",
    "        return self.alpha*np.sum(np.abs(w))\n",
    "    def derivation(self,w):\n",
    "        return self.alpha*np.sign(w)\n",
    "\n",
    "class Lasso(LinearRegression):\n",
    "    def __init__(self,alpha,learning_rate=0.1,iteration=5000):\n",
    "        \"\"\"Lasso Regression implementation - inherits Linear Regression\n",
    "        alpha - hyperparameter\n",
    "        Learning_rate = rate of gradient descent reaching minima\n",
    "        iteration = number of iteration - (can only be integer)\n",
    "        \"\"\"\n",
    "        self.regularization=Lassopenalty(alpha)\n",
    "        #initialize the Ridge penalty\n",
    "        \n",
    "        super().__init__(learning_rate,iteration)\n",
    "        #initialize the super class i.e LinearRegression\n",
    "\n",
    "    def _calculate_cost(self, y, y_pred):\n",
    "        return super()._calculate_cost(y,y_pred)+self.regularization(self.weights)\n",
    "    #cost function \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.samples,self.features=X.shape\n",
    "        super()._init_params()\n",
    "        for i in range(self.itr):\n",
    "            y_pred=super()._get_prediction(X)\n",
    "            cost=self._calculate_cost(y,y_pred)\n",
    "            dw,db=super()._get_gradient(X,y,y_pred)\n",
    "            dw+=self.regularization.derivation(self.weights)\n",
    "            self._update_params(dw,db)\n",
    "            if i % 100 ==0:\n",
    "                print(f\"The Cost in iteration {i}----->{cost}\")\n",
    "                \n",
    "    def predict(self,X):\n",
    "        return super().predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a538427",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">ElasticNet (L1 and L2 Regularization) </h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eb82a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ElasticNetPenalty(LassoPenalty,RidgePenalty):\n",
    "    \"\"\"ElasticNet Regularization class -inherits Lasso and Ridge penalty\"\"\"\n",
    "    def __init__(self,l1_ratio,alpha):\n",
    "        self.l1_ratio=l1_ratio\n",
    "        self.Lasso=LassoPenalty(alpha)\n",
    "        self.Ridge=RidgePenalty(alpha)\n",
    "    def cost(self,w):\n",
    "        return (self.l1_ratio)*(self.Lasso(w)) +(1-self.l1_ratio)*(self.Ridge(w))\n",
    "    def derivation(self,w):\n",
    "        return (self.l1_ratio)*(self.Lasso.derivation(w)) +(1-self.l1_ratio)*(self.Ridge.derivation(w))\n",
    "    \n",
    "    \n",
    "class ElasticNet(LinearRegression):\n",
    "    def __init__(self,alpha,l1_ratio, learning_rate=0.01, iteration=3000):\n",
    "        \"\"\"Elastic Net Regression implementation - inherits Linear Regression\n",
    "        alpha - hyperparameter\n",
    "        L1_ratio- ratio of penalty\n",
    "        Learning_rate = rate of gradient descent reaching minima\n",
    "        iteration = number of iteration - (can only be integer) \"\"\"\n",
    "        self.regularization=ElasticNetPenalty(alpha,l1_ratio)\n",
    "        #initialize the Elastic Net penalty\n",
    "        \n",
    "        super().__init__(learning_rate, iteration)\n",
    "        #initialize the super class i.e LinearRegression\n",
    "        \n",
    "    def _calculate_cost(self, y, y_pred):\n",
    "        return super()._calculate_cost(y, y_pred)+self.regularization.cost(self.weights)\n",
    "    #cost function\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.samples,self.features=X.shape\n",
    "        self._init_params()\n",
    "        for i in range(self.itr):\n",
    "            y_pred=super()._get_prediction(X)\n",
    "            cost=self._calculate_cost(y,y_pred)\n",
    "            dw,db=super()._get_gradient(X,y,y_pred)\n",
    "            dw+=self.regularization.derivation(self.weights)\n",
    "            self._update_params(dw,db)\n",
    "            if i % 100 ==0:\n",
    "                print(f\"The Cost in iteration {i}----->{cost}\")\n",
    "                \n",
    "    def predict(self,X):\n",
    "        return super().predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a7237",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "    <h2 style=\"margin:150px\"></h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6cbe76",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Test Train split</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6e262436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12c710",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Applying Standardization</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9bccc0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "st=StandardScaler()\n",
    "X_train=st.fit_transform(X_train)\n",
    "X_test=st.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173eab5b",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "    <h2 style=\"margin:300px\"></h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941483e2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Implementing Linear Regression regression</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "890f5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 0----->297.37484615384614\n",
      "The Cost in iteration 100----->11.67190100608827\n",
      "The Cost in iteration 200----->11.564670476056179\n",
      "The Cost in iteration 300----->11.544346117022767\n",
      "The Cost in iteration 400----->11.539036888946223\n",
      "The Cost in iteration 500----->11.53757302292186\n",
      "The Cost in iteration 600----->11.537166351224284\n",
      "The Cost in iteration 700----->11.537053259251122\n",
      "The Cost in iteration 800----->11.537021804943727\n",
      "The Cost in iteration 900----->11.537013056381053\n",
      "The Cost in iteration 1000----->11.537010623088031\n",
      "The Cost in iteration 1100----->11.53700994630063\n",
      "The Cost in iteration 1200----->11.537009758061398\n",
      "The Cost in iteration 1300----->11.53700970570521\n",
      "The Cost in iteration 1400----->11.537009691143046\n",
      "The Cost in iteration 1500----->11.537009687092775\n",
      "The Cost in iteration 1600----->11.537009685966249\n",
      "The Cost in iteration 1700----->11.537009685652919\n",
      "The Cost in iteration 1800----->11.53700968556577\n",
      "The Cost in iteration 1900----->11.537009685541534\n",
      "The Cost in iteration 2000----->11.537009685534793\n",
      "The Cost in iteration 2100----->11.537009685532917\n",
      "The Cost in iteration 2200----->11.537009685532396\n",
      "The Cost in iteration 2300----->11.537009685532249\n",
      "The Cost in iteration 2400----->11.53700968553221\n",
      "The Cost in iteration 2500----->11.537009685532198\n",
      "The Cost in iteration 2600----->11.537009685532196\n",
      "The Cost in iteration 2700----->11.537009685532194\n",
      "The Cost in iteration 2800----->11.537009685532194\n",
      "The Cost in iteration 2900----->11.537009685532194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8284494153200391"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "LR=LinearRegression(0.1,3000)\n",
    "LR.fit(X_train,y_train)\n",
    "y_predict=LR.predict(X_test)\n",
    "r2_score(y_test,y_predict)\n",
    "#calculating R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d909cea",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "    <h2 style=\"margin:50px\"></h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37646f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Implementing Ridge regression</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "496db407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 0----->297.37484615384614\n",
      "The Cost in iteration 100----->15.120786743885096\n",
      "The Cost in iteration 200----->15.120095832846003\n",
      "The Cost in iteration 300----->15.12009380384473\n",
      "The Cost in iteration 400----->15.120093794922692\n",
      "The Cost in iteration 500----->15.120093794880631\n",
      "The Cost in iteration 600----->15.120093794880432\n",
      "The Cost in iteration 700----->15.120093794880432\n",
      "The Cost in iteration 800----->15.120093794880432\n",
      "The Cost in iteration 900----->15.120093794880434\n",
      "The Cost in iteration 1000----->15.120093794880432\n",
      "The Cost in iteration 1100----->15.120093794880432\n",
      "The Cost in iteration 1200----->15.120093794880432\n",
      "The Cost in iteration 1300----->15.120093794880432\n",
      "The Cost in iteration 1400----->15.120093794880432\n",
      "The Cost in iteration 1500----->15.120093794880432\n",
      "The Cost in iteration 1600----->15.120093794880432\n",
      "The Cost in iteration 1700----->15.120093794880432\n",
      "The Cost in iteration 1800----->15.120093794880432\n",
      "The Cost in iteration 1900----->15.120093794880432\n",
      "The Cost in iteration 2000----->15.120093794880432\n",
      "The Cost in iteration 2100----->15.120093794880432\n",
      "The Cost in iteration 2200----->15.120093794880432\n",
      "The Cost in iteration 2300----->15.120093794880432\n",
      "The Cost in iteration 2400----->15.120093794880432\n",
      "The Cost in iteration 2500----->15.120093794880432\n",
      "The Cost in iteration 2600----->15.120093794880432\n",
      "The Cost in iteration 2700----->15.120093794880432\n",
      "The Cost in iteration 2800----->15.120093794880432\n",
      "The Cost in iteration 2900----->15.120093794880432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8395354974625773"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RID=Ridge(0.1,0.1,3000)\n",
    "RID.fit(X_train,y_train)\n",
    "y_predict=RID.predict(X_test)\n",
    "r2_score(y_test,y_predict)\n",
    "#calculating R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a55701",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "    <h2 style=\"margin:80px\"></h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d32562",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Implementing Lasso regression</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "01f6548f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 0\n",
      "The Cost in iteration 0----->297.37484615384614\n",
      "The Cost in iteration 100----->11.692540906723025\n",
      "The Cost in iteration 200----->11.586345947111166\n",
      "The Cost in iteration 300----->11.566492612686854\n",
      "The Cost in iteration 400----->11.561384650016578\n",
      "The Cost in iteration 500----->11.559976757478516\n",
      "The Cost in iteration 600----->11.559585646519556\n",
      "The Cost in iteration 700----->11.559476882111507\n",
      "The Cost in iteration 800----->11.559446631437059\n",
      "The Cost in iteration 900----->11.559438217647685\n",
      "The Cost in iteration 1000----->11.559435877467282\n",
      "The Cost in iteration 1100----->11.559435226577888\n",
      "The Cost in iteration 1200----->11.559435045541834\n",
      "The Cost in iteration 1300----->11.559434995189111\n",
      "The Cost in iteration 1400----->11.559434981184188\n",
      "The Cost in iteration 1500----->11.559434977288907\n",
      "The Cost in iteration 1600----->11.559434976205488\n",
      "The Cost in iteration 1700----->11.559434975904146\n",
      "The Cost in iteration 1800----->11.559434975820334\n",
      "The Cost in iteration 1900----->11.559434975797023\n",
      "The Cost in iteration 2000----->11.55943497579054\n",
      "The Cost in iteration 2100----->11.559434975788738\n",
      "The Cost in iteration 2200----->11.559434975788237\n",
      "The Cost in iteration 2300----->11.559434975788095\n",
      "The Cost in iteration 2400----->11.559434975788058\n",
      "The Cost in iteration 2500----->11.559434975788049\n",
      "The Cost in iteration 2600----->11.559434975788044\n",
      "The Cost in iteration 2700----->11.559434975788044\n",
      "The Cost in iteration 2800----->11.559434975788042\n",
      "The Cost in iteration 2900----->11.55943497578804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8285684447316505"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAS=Lasso(0.001,0.1,3000)\n",
    "LAS.fit(X_train,y_train)\n",
    "y_predict=LAS.predict(X_test)\n",
    "r2_score(y_test,y_predict)\n",
    "#calculating R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50149cd5",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "    <h2 style=\"margin:80px\"></h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30bcd20",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <h2 style=\"margin:0px\">Implementing ElasticNet regression</h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "214d3d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 0----->297.37484615384614\n",
      "The Cost in iteration 100----->238.55724915526173\n",
      "The Cost in iteration 200----->196.5167857619539\n",
      "The Cost in iteration 300----->163.7835403569911\n",
      "The Cost in iteration 400----->137.53070692882102\n",
      "The Cost in iteration 500----->116.25817046921699\n",
      "The Cost in iteration 600----->98.9474792872051\n",
      "The Cost in iteration 700----->84.83508525561747\n",
      "The Cost in iteration 800----->73.31821957291808\n",
      "The Cost in iteration 900----->63.91301557224504\n",
      "The Cost in iteration 1000----->56.228372237412245\n",
      "The Cost in iteration 1100----->49.947068020790695\n",
      "The Cost in iteration 1200----->44.811249157916606\n",
      "The Cost in iteration 1300----->40.61099804670377\n",
      "The Cost in iteration 1400----->37.175223526973454\n",
      "The Cost in iteration 1500----->34.364353638801525\n",
      "The Cost in iteration 1600----->32.06444810328093\n",
      "The Cost in iteration 1700----->30.18243893171322\n",
      "The Cost in iteration 1800----->28.642273059356533\n",
      "The Cost in iteration 1900----->27.381971836583634\n",
      "The Cost in iteration 2000----->26.350604235727587\n",
      "The Cost in iteration 2100----->25.506426701127154\n",
      "The Cost in iteration 2200----->24.81544117609284\n",
      "The Cost in iteration 2300----->24.2498320502577\n",
      "The Cost in iteration 2400----->23.786840872769833\n",
      "The Cost in iteration 2500----->23.40784744621879\n",
      "The Cost in iteration 2600----->23.097605976917247\n",
      "The Cost in iteration 2700----->22.843641558175925\n",
      "The Cost in iteration 2800----->22.63574371991281\n",
      "The Cost in iteration 2900----->22.465558039071183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7882085812445028"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELN=ElasticNet(0.1,0.5,0.001,3000)\n",
    "ELN.fit(X_train,y_train)\n",
    "y_predict=ELN.predict(X_test)\n",
    "r2_score(y_test,y_predict)\n",
    "#calculating R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafff5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
